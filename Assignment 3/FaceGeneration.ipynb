{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Reshape\n",
    "from keras.layers.core import Flatten\n",
    "from keras.optimizers import SGD\n",
    "from keras.datasets import mnist\n",
    "import matplotlib.image as matimg\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import UpSampling2D\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import argparse\n",
    "import math\n",
    "from keras.optimizers import Adam\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(path):\n",
    "    img = matimg.imread(\"C:\\\\Users\\\\Trupti\\\\Desktop\\\\img_align_celeba\")\n",
    "    return img\n",
    "\n",
    "#following code loads data from local repo\n",
    "#directory should have two subfolders, with name train and test\n",
    "def load_local_data(path):\n",
    "    paths = glob.glob(os.path.join(path + \"/train\", \"*.jpg\"))\n",
    "    X_train = np.array( [ load_image(p) for p in paths ] )\n",
    "\n",
    "    paths = glob.glob(os.path.join(path + \"/test\", \"*.jpg\"))\n",
    "    X_test = np.array( [ load_image(p) for p in paths ] )\n",
    "   \n",
    "    return X_train, X_test\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Note: This code is for 32x32 colored image\n",
    "def generator_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(input_dim=100, output_dim=1024))\n",
    "    model.add(Activation('tanh'))\n",
    "    model.add(Dense(128*8*8))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('tanh'))\n",
    "    model.add(Reshape((128, 8, 8), input_shape=(128*8*8,)))\n",
    "    model.add(UpSampling2D(size=(2, 2)))\n",
    "    model.add(Convolution2D(64, 5, 5, border_mode='same'))\n",
    "    model.add(Activation('tanh'))\n",
    "    model.add(UpSampling2D(size=(2, 2)))\n",
    "    model.add(Convolution2D(3, 5, 5, border_mode='same'))\n",
    "    model.add(Activation('tanh'))\n",
    "    return model\n",
    "\n",
    "#Note: This code is for 32x32 colored image\n",
    "def discriminator_model():\n",
    "    model = Sequential()\n",
    "    model.add(Convolution2D(\n",
    "                        64, 5, 5,\n",
    "                        border_mode='same',\n",
    "                        input_shape=(3, 32, 32)))\n",
    "    model.add(Activation('tanh'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Convolution2D(128, 5, 5))\n",
    "    model.add(Activation('tanh'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1024))\n",
    "    model.add(Activation('tanh'))\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('sigmoid'))\n",
    "    return model\n",
    "\n",
    "    #dummy_input = np.ones((1, 1, 28, 28))   \n",
    "    # For TensorFlow dummy_input = np.ones((32, 12, 12, 3))\n",
    "    #preds = model.predict(dummy_input)\n",
    "    #print(preds.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_containing_discriminator(generator, discriminator):\n",
    "    model = Sequential()\n",
    "    model.add(generator)\n",
    "    discriminator.trainable = False\n",
    "    model.add(discriminator)\n",
    "    return model\n",
    "\n",
    "\n",
    "def combine_images(generated_images):\n",
    "    num = generated_images.shape[0]\n",
    "    width = int(math.sqrt(num))\n",
    "    height = int(math.ceil(float(num)/width))\n",
    "    generated_images = generated_images.reshape((generated_images.shape[0], 32, 32, 3) )\n",
    "    shape = generated_images.shape[1:3]\n",
    "    image = np.zeros((height*shape[0], width*shape[1], 3),\n",
    "                     dtype=generated_images.dtype)\n",
    "    for index, img in enumerate(generated_images):\n",
    "        i = int(index/width)\n",
    "        j = index % width\n",
    "        image[i*shape[0]:(i+1)*shape[0], j*shape[1]:(j+1)*shape[1], 0] = \\\n",
    "            img[:, :, 0]\n",
    "    image[i*shape[0]:(i+1)*shape[0], j*shape[1]:(j+1)*shape[1], 1] = \\\n",
    "            img[:, :, 1]\n",
    "    image[i*shape[0]:(i+1)*shape[0], j*shape[1]:(j+1)*shape[1], 2] = \\\n",
    "            img[:, :, 2]\n",
    "    return image\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(BATCH_SIZE):\n",
    "    #path to dataset\n",
    "    path=\"C:\\\\Users\\\\Trupti\\\\Desktop\\\\img_align_celeba\"\n",
    "    (X_train, X_test) = load_local_data(path)\n",
    "\n",
    "    X_train = (X_train.astype(np.float32) - 127.5)/127.5\n",
    "    print (X_train.shape)\n",
    "    X_train = X_train.reshape((X_train.shape[0], 3) + X_train.shape[1:3])\n",
    "    print (X_train.shape)\n",
    "    discriminator = discriminator_model()\n",
    "    generator = generator_model()\n",
    "    discriminator_on_generator = \\\n",
    "        generator_containing_discriminator(generator, discriminator)\n",
    "    d_optim = Adam(lr=0.0002, beta_1=0.5)\n",
    "    g_optim = Adam(lr=0.0002, beta_1=0.5)\n",
    "    generator.compile(loss='binary_crossentropy', optimizer=g_optim)\n",
    "    discriminator_on_generator.compile(\n",
    "        loss='binary_crossentropy', optimizer=g_optim)\n",
    "    discriminator.trainable = True\n",
    "    discriminator.compile(loss='binary_crossentropy', optimizer=d_optim)\n",
    "    noise = np.zeros((BATCH_SIZE, 100))\n",
    "\n",
    "    for epoch in range(10):\n",
    "        print(\"Epoch is\", epoch)\n",
    "        print(\"Number of batches\", int(X_train.shape[0]/BATCH_SIZE))\n",
    "\t# load weights on first try (i.e. if process failed previously and we are attempting to recapture lost data)\n",
    "        if epoch == 0:\n",
    "            if os.path.exists('generator') and os.path.exists('discriminator'):\n",
    "                print (\"Loading saves weights..\")\n",
    "                generator.load_weights('generator')\n",
    "                discriminator.load_weights('discriminator')\n",
    "                print (\"Finished loading\")\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "        for index in range(int(X_train.shape[0]/BATCH_SIZE)):\n",
    "            for i in range(BATCH_SIZE):\n",
    "                noise[i, :] = np.random.uniform(-1, 1, 100)\n",
    "            image_batch = X_train[index*BATCH_SIZE:(index+1)*BATCH_SIZE]\n",
    "            generated_images = generator.predict(noise, verbose=0)\n",
    "            if index % 20 == 0:\n",
    "                image = combine_images(generated_images)\n",
    "                image = image*127.5+127.5\n",
    "                Image.fromarray(image.astype(np.uint8)).save(\n",
    "                    str(epoch)+\"_\"+str(index)+\".png\")\n",
    "            X = np.concatenate((image_batch, generated_images))\n",
    "            y = [1] * BATCH_SIZE + [0] * BATCH_SIZE\n",
    "            d_loss = discriminator.train_on_batch(X, y)\n",
    "            print(\"batch %d d_loss : %f\" % (index, d_loss))\n",
    "            for i in range(BATCH_SIZE):\n",
    "                noise[i, :] = np.random.uniform(-1, 1, 100)\n",
    "            discriminator.trainable = False\n",
    "            g_loss = discriminator_on_generator.train_on_batch(\n",
    "                noise, [1] * BATCH_SIZE)\n",
    "            discriminator.trainable = True\n",
    "            print(\"batch %d g_loss : %f\" % (index, g_loss))\n",
    "            if index % 10 == 9:\n",
    "                generator.save_weights('generator', True)\n",
    "                discriminator.save_weights('discriminator', True)\n",
    "\n",
    "def generate(BATCH_SIZE):\n",
    "    generator = generator_model()\n",
    "    d_optim = Adam(lr=0.0002, beta_1=0.5)\n",
    "    g_optim = Adam(lr=0.0002, beta_1=0.5)\n",
    "    generator.compile(loss='binary_crossentropy', optimizer=g_optim)\n",
    "    generator.load_weights('generator')\n",
    "    noise = np.zeros((BATCH_SIZE, 100))\n",
    "    for i in range(BATCH_SIZE):\n",
    "    \tnoise[i, :] = np.random.uniform(-1, 1, 100)\n",
    "    generated_images = generator.predict(noise, verbose=1)\n",
    "    image = combine_images(generated_images)\n",
    "    image = image*127.5+127.5\n",
    "    Image.fromarray(image.astype(np.uint8)).save(\n",
    "        \"generated_image.png\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--mode MODE] [--batch_size BATCH_SIZE]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f C:\\Users\\Trupti\\AppData\\Roaming\\jupyter\\runtime\\kernel-98485c18-5248-48b6-b6af-4d206873b3d8.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Trupti\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2870: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "#to run this code give this command: \"python dcgan_face.py --mode train --batch_size 128\"\n",
    "def get_args():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--mode\", type=str)\n",
    "    parser.add_argument(\"--batch_size\", type=int, default=128)\n",
    "    args = parser.parse_args()\n",
    "    return args\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    args = get_args()\n",
    "    if args.mode == \"train\":\n",
    "        train(BATCH_SIZE=args.batch_size)\n",
    "    elif args.mode == \"generate\":\n",
    "        generate(BATCH_SIZE=args.batch_size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
